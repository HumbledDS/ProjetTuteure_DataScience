{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJET TUTEURE : \n",
    "\n",
    "Réseaux de neurones : contact Gilles Michel : gilles.michel@sudintralog.com \n",
    "Récupération sur Yahoo Finances, par API, des cours de clôture d'une liste d'actions contenues  dans un fichier CSV, depuis le 1er janvier au 31 décembre 2021. \n",
    "Stocker ces cours dans une  base de données. Utiliser un réseau de neurones sur la période du 01/01/2022 au 31/08/2022 pour prédire le cours ou le sens d'évolution de chaque action du 01/09/2022 au 31/12/2022.  \n",
    "Générer un fichier CSV par action représentant une simulation de trading sur la période du  01/09/2022 au 31/12/2022 avec une base de 1 million d'euros par action au 01/09/2022. On  prendra des frais de broker de 0.01€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMZN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBNP.PA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIR.PA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOR.PA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTE.DE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMW.DE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApple Inc.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMicrosoft Corporation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlphabet Inc.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmazon.com Inc.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesla Inc.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBNP Paribas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirbus SE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOréal S.A.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeutsche Telekom AG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayerische Motoren Werke AG (BMW)\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAC40\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAC40\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAC40\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAX\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m actions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Symbol\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"BNP.PA\", \"AIR.PA\", \"OR.PA\", \"DTE.DE\", \"BMW.DE\"],\n",
    "    \"Name\": [\"Apple Inc.\", \"Microsoft Corporation\", \"Alphabet Inc.\", \"Amazon.com Inc.\", \"Tesla Inc.\", \"BNP Paribas\", \"Airbus SE\", \"L'Oréal S.A.\", \"Deutsche Telekom AG\", \"Bayerische Motoren Werke AG (BMW)\"],\n",
    "    \"Index\": [\"S&P500\", \"S&P500\", \"S&P500\", \"S&P500\", \"S&P500\", \"CAC40\", \"CAC40\", \"CAC40\", \"DAX\", \"DAX\"]\n",
    "}\n",
    "\n",
    "actions_df = pd.DataFrame(data)\n",
    "\n",
    "# Sauvegarder les données dans un fichier CSV\n",
    "actions_df.to_csv('actions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 1 : Récupération des données\n",
    "Nous devons lire le fichier CSV contenant la liste des actions et utiliser l'API Yahoo Finance pour récupérer les cours de clôture. Voici comment nous pouvons procéder :\n",
    "\n",
    "Lire le fichier CSV :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer les données de Yahoo Finance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fonction pour récupérer les données de clôture des actions\n",
    "def get_stock_data(symbol, start_date, end_date):\n",
    "    stock = yf.Ticker(symbol)\n",
    "    hist = stock.history(start=start_date, end=end_date)\n",
    "    return hist['Close']\n",
    "\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-12-31'\n",
    "stock_data = {}\n",
    "\n",
    "for symbol in actions_list:\n",
    "    stock_data[symbol] = get_stock_data(symbol, start_date, end_date)\n",
    "\n",
    "# Convertir les données en DataFrame\n",
    "stock_data_df = pd.DataFrame(stock_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocker les données dans une base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Créer une connexion à la base de données\n",
    "engine = create_engine('sqlite:///stock_data.db')\n",
    "\n",
    "# Stocker les données dans une table\n",
    "stock_data_df.to_sql('stock_prices', con=engine, if_exists='replace', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 2 : Préparation des données\n",
    "Nous devons préparer les données pour l'entraînement du modèle de réseau de neurones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyage et transformation des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(stock_data_df)\n",
    "\n",
    "# Créer des ensembles d'entraînement et de test\n",
    "train_data = scaled_data[:int(len(scaled_data)*0.8)]\n",
    "test_data = scaled_data[int(len(scaled_data)*0.8):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 3 : Modélisation avec un réseau de neurones\n",
    "Nous allons utiliser Keras pour créer et entraîner un modèle de réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création et entraînement du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 1\n",
    "X_train, Y_train = create_dataset(train_data, look_back)\n",
    "X_test, Y_test = create_dataset(test_data, look_back)\n",
    "\n",
    "# Reshape des données pour LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# Prédictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étape 4 : Simulation de trading\n",
    "Nous allons utiliser les prédictions pour simuler des transactions de trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation de trading et génération de fichiers CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capital = 1000000\n",
    "broker_fee = 0.01\n",
    "\n",
    "def simulate_trading(predictions, initial_capital):\n",
    "    capital = initial_capital\n",
    "    for i in range(len(predictions)-1):\n",
    "        # Acheter à la prédiction actuelle et vendre à la prochaine\n",
    "        if predictions[i+1] > predictions[i]:\n",
    "            # Acheter\n",
    "            shares = capital / predictions[i]\n",
    "            capital = shares * predictions[i+1] - broker_fee\n",
    "        else:\n",
    "            capital -= broker_fee\n",
    "    return capital\n",
    "\n",
    "trading_results = {}\n",
    "\n",
    "for symbol in stock_data_df.columns:\n",
    "    predictions = model.predict(stock_data_df[symbol].values.reshape(-1, 1))\n",
    "    final_capital = simulate_trading(predictions, initial_capital)\n",
    "    trading_results[symbol] = final_capital\n",
    "\n",
    "# Sauvegarder les résultats dans des fichiers CSV\n",
    "for symbol, capital in trading_results.items():\n",
    "    result_df = pd.DataFrame({'Symbol': [symbol], 'Final Capital': [capital]})\n",
    "    result_df.to_csv(f'results_{symbol}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
